{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133c5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV # ハイパーパラメータチューニングと交差検証を自動で行うためのライブラリ\n",
    "from sklearn.ensemble import RandomForestClassifier # ランダムフォレスト\n",
    "import lightgbm as gbm # LightGBM\n",
    "import xgboost as xgb # XGBoost\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_rows', 20)\n",
    "np.set_printoptions(threshold = np.inf)\n",
    "device = 'CPU' # GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d26e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_alpha_from_prefix(cabins):\n",
    "    if pd.isna(cabins):\n",
    "        return cabins\n",
    "\n",
    "    alpha_part = \"\"\n",
    "    for cabin in cabins.split(' '):\n",
    "        for char in cabin:\n",
    "            if char.isalpha():\n",
    "                alpha_part += char\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    for i in range(len(alpha_part)-1):\n",
    "        if alpha_part[i] != alpha_part[i+1]:\n",
    "            return alpha_part\n",
    "\n",
    "    return alpha_part[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55797c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(df_all):\n",
    "    # 3.1.1 Name -> Title\n",
    "    df_all['Title'] = df_all['Name'].str.split(',', expand = True)[1].str.split('.', expand = True)[0].str.strip()\n",
    "\n",
    "    # 出現回数が非常に少ないタイトルは過学習の原因になるので、似ている特性でカテゴライズする\n",
    "    # (Miss、Mrs、)Ms、Mlle、Lady、Mme、The Countess、Donaはすべて女性であるため、Miss/Mrs/Msに置き換える\n",
    "    df_all['Title'] = df_all['Title'].replace(['Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "    df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "    # 3.1.2 Ticket -> Ticket Frequency\n",
    "    df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')\n",
    "\n",
    "\n",
    "    # Cabin -> Segment\n",
    "    df_all['Segment'] = df_all['Cabin'].apply(extract_alpha_from_prefix)\n",
    "\n",
    "    # 特徴量同士を組み合わせる\n",
    "    df_all['Family'] = df_all['SibSp'] + df_all['Parch']\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05abb801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_with_eda(data, label_encoders = None, ct = None):\n",
    "    # 欠損値の処理(fillna関数のinplace = Trueは、PandasのDataFrameやSeriesのメソッドで使用される引数で、元のDataFrameまたはSeriesを直接変更することを指定)\n",
    "    data['Age'] = data['Age'].fillna(data['Age'].median())\n",
    "    data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "    data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "\n",
    "    # 特徴量の部分抽出\n",
    "    data = eda(data)\n",
    "    remove_columns = ['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch']\n",
    "    data = data.drop(columns = remove_columns)\n",
    "    data_columns = data.columns.tolist()\n",
    "    data_index = data.index\n",
    "\n",
    "    # カテゴリ変数を数値に変換\n",
    "    # LabelEncodeing(カテゴリ変数が特定の順番を持つ場合)\n",
    "    le_columns = ['Segment'] # 'Embarked'\n",
    "    if not label_encoders:\n",
    "        label_encoders = {}\n",
    "        for column in le_columns:\n",
    "            le = LabelEncoder()\n",
    "            data[column] = le.fit_transform(data[column])\n",
    "            label_encoders[column] = le\n",
    "    else:\n",
    "        for column in le_columns:\n",
    "            data[column] = label_encoders[column].transform(data[column])\n",
    "\n",
    "    # # OneHotEncoding(カテゴリ変数が特定の順番を持たない場合)\n",
    "    # ohe_columns = ['Sex', 'Title', 'Embarked']\n",
    "    # if not ct:\n",
    "    #     ct = ColumnTransformer(\n",
    "    #         transformers = [(\n",
    "    #             'encoder',\n",
    "    #             OneHotEncoder(handle_unknown = 'ignore', sparse_output = False),\n",
    "    #             ohe_columns\n",
    "    #         )],\n",
    "    #         remainder = 'passthrough'\n",
    "    #     )\n",
    "    #     data = ct.fit_transform(data)\n",
    "    # else:\n",
    "    #     data = ct.transform(data)\n",
    "\n",
    "    # encoded_feature_names = ct.named_transformers_['encoder'].get_feature_names_out(ohe_columns) # OneHotEncoderによって生成された新しい列名を取得\n",
    "    # passthrough_columns = [col for col in data_columns if col not in ohe_columns] # remainder='passthrough' でそのまま通過した列の名前を取得\n",
    "    # all_feature_names = list(encoded_feature_names) + passthrough_columns\n",
    "    # data = pd.DataFrame(data, columns = all_feature_names, index = data_index)\n",
    "\n",
    "    # 整数型に戻したいカラムのリストを定義\n",
    "    int_columns = ['PassengerId', 'Survived']\n",
    "    for col in int_columns:\n",
    "        if col in data.columns:\n",
    "            data[col] = data[col].astype(int)\n",
    "\n",
    "    return data, label_encoders, ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a85315a",
   "metadata": {},
   "source": [
    "## 学習用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854981dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データロード\n",
    "train_data = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e0e46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'Ticket_Frequency',\n",
      "       'Segment', 'Family'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop(columns = ['Survived', 'PassengerId'])\n",
    "y = train_data['Survived']\n",
    "X, le_encoders, ct = transform_data_with_eda(X)\n",
    "print(X.columns)\n",
    "# remove_columns = ['Sex_male', 'Title_Mrs', 'Embarked_S']\n",
    "# X = X.drop(columns = remove_columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da18b2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Ticket_Frequency</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Dr/Military/Noble/Clergy</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age     Fare Embarked                     Title  \\\n",
       "0         3    male  22.0   7.2500        S                        Mr   \n",
       "1         1  female  38.0  71.2833        C                       Mrs   \n",
       "2         3  female  26.0   7.9250        S                      Miss   \n",
       "3         1  female  35.0  53.1000        S                       Mrs   \n",
       "4         3    male  35.0   8.0500        S                        Mr   \n",
       "..      ...     ...   ...      ...      ...                       ...   \n",
       "886       2    male  27.0  13.0000        S  Dr/Military/Noble/Clergy   \n",
       "887       1  female  19.0  30.0000        S                      Miss   \n",
       "888       3  female  28.0  23.4500        S                      Miss   \n",
       "889       1    male  26.0  30.0000        C                        Mr   \n",
       "890       3    male  32.0   7.7500        Q                        Mr   \n",
       "\n",
       "     Ticket_Frequency  Segment  Family  \n",
       "0                   1       10       1  \n",
       "1                   1        2       1  \n",
       "2                   1       10       0  \n",
       "3                   2        2       1  \n",
       "4                   1       10       0  \n",
       "..                ...      ...     ...  \n",
       "886                 1       10       0  \n",
       "887                 1        1       0  \n",
       "888                 2       10       3  \n",
       "889                 1        2       0  \n",
       "890                 1       10       0  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb4ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- フィーチャースケーリング ---\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dae9215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bagging_temperature': 0, 'depth': 7, 'l2_leaf_reg': 7, 'learning_rate': 0.5, 'random_strength': 1, 'rsm': 1}\n",
      "Best Score: 0.8724310851073094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nランダムフォレスト\\nBest Parameters: {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\\nBest Score: 0.8385367762128325\\n\\nLightBGM\\nBest Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'num_leaves': 10, 'subsample': 0.6}\\nBest Score: 0.8314488328572835\\n\\nXGBoost\\nBest Parameters: {'colsample_bytree': 0.5, 'gamma': 0.5, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 250, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.75}\\nBest Score: 0.8454840933714174\\n\\nBest Parameters: {'bagging_temperature': 0, 'depth': 7, 'l2_leaf_reg': 7, 'learning_rate': 0.5, 'random_strength': 1, 'rsm': 1}\\nBest Score: 0.8724310851073094\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- モデルの訓練 ---\n",
    "# 試したいパラメータの候補を辞書で定義\n",
    "categorical_features = ['Sex', 'Embarked', 'Title']\n",
    "param_grid_cat = {\n",
    "    # 'iterations': [1000, 1200, 1400],\n",
    "    'learning_rate': [0.5],\n",
    "    'depth': [7],\n",
    "    'l2_leaf_reg': [7],\n",
    "    'bagging_temperature': [0],\n",
    "    'random_strength': [1],\n",
    "    'rsm': [1],\n",
    "}\n",
    "\n",
    "# モデルとパラメータ候補、交差検証の方法を指定してGridSearchCVを準備\n",
    "# cv=5 は5-Fold Cross-Validationを意味する\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = CatBoostClassifier(random_state = 0, verbose = 0, cat_features = categorical_features, eval_metric = 'AUC', task_type = device),\n",
    "    param_grid = param_grid_cat,\n",
    "    cv = 5,\n",
    "    scoring = 'roc_auc'\n",
    ")\n",
    "\n",
    "# 訓練データで探索を実行\n",
    "grid_search.fit(X_train, y_train, eval_set = [(X_test, y_test)], early_stopping_rounds = 50)\n",
    "\n",
    "# 最も性能が良かったパラメータとスコアを確認\n",
    "best_params_R = grid_search.best_params_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "\"\"\"\n",
    "ランダムフォレスト\n",
    "Best Parameters: {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
    "Best Score: 0.8385367762128325\n",
    "\n",
    "LightBGM\n",
    "Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'num_leaves': 10, 'subsample': 0.6}\n",
    "Best Score: 0.8314488328572835\n",
    "\n",
    "XGBoost\n",
    "Best Parameters: {'colsample_bytree': 0.5, 'gamma': 0.5, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 250, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.75}\n",
    "Best Score: 0.8454840933714174\n",
    "\n",
    "Best Parameters: {'bagging_temperature': 0, 'depth': 7, 'l2_leaf_reg': 7, 'learning_rate': 0.5, 'random_strength': 1, 'rsm': 1}\n",
    "Best Score: 0.8724310851073094\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b0f601",
   "metadata": {},
   "source": [
    "## 提出用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532b0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データロード\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# データの前処理\n",
    "X_train = train_data.drop(columns = ['Survived', 'PassengerId'])\n",
    "y_train = train_data['Survived']\n",
    "X_test = test_data.drop(columns = ['PassengerId'])\n",
    "X_train, le_encoders, ct = transform_data_with_eda(X_train)\n",
    "X_test, _, _ = transform_data_with_eda(X_test, le_encoders, ct)\n",
    "# remove_columns = ['Sex_male', 'Title_Mrs', 'Embarked_S']\n",
    "# X_train = X_train.drop(columns = remove_columns)\n",
    "# X_test = X_test.drop(columns = remove_columns)\n",
    "\n",
    "# --- フィーチャースケーリング ---\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# --- 最適なパラメータでのモデル訓練 ---\n",
    "classifier = CatBoostClassifier(random_state = 0, verbose = 0, cat_features = categorical_features, eval_metric = 'AUC', task_type = device, **best_params_R)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "X_test_passengerid = test_data['PassengerId'].values\n",
    "\n",
    "survived_passenger = pd.DataFrame({\n",
    "    'PassengerId': X_test_passengerid,\n",
    "    'Survived': y_pred\n",
    "})\n",
    "survived_passenger.to_csv('./data/submittion_catboost.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7369a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-DIVfiPaQ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
